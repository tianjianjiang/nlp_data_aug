{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDb_baseline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aewJdyop_-hx",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tianjianjiang/nlp_data_aug/blob/master/IMDb_baselne.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9LbB0krq6z2",
        "colab_type": "text"
      },
      "source": [
        "# Prepare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMnqAd1HJ1Br",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "* [fastai/course-v3/nbs/dl1/lesson3-imdb.ipynb](https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson3-imdb.ipynb) (2019-05-03)\n",
        "\n",
        "learner|bs|lr  |bptt|wd  |drop_mult|`to_fp16(clip)`|fw acc%\n",
        "--     |-:|--: |--: |--: |--:      |--             |--:\n",
        "lm     |48|1e-2|70  |0.01|0.3      |No             |34.1371\n",
        "cf     |48|2e-2|70  |0.01|0.5      |No             |94.3960\n",
        "\n",
        "* [fastai/fastai/examples/ULMFit.ipynb](https://nbviewer.jupyter.org/github/fastai/fastai/blob/master/examples/ULMFit.ipynb) (2019-06-11)\n",
        "\n",
        "  > Fine-tuning a forward and backward langauge model to get to 95.4% accuracy on the IMDB movie reviews dataset. This tutorial is done with fastai v1.0.53.\n",
        "\n",
        "  > The example was run on a Titan RTX (24 GB of RAM) so you will probably need to adjust the batch size accordinly. If you divide it by 2, don't forget to divide the learning rate by 2 as well in the following cells. You can also reduce a little bit the bptt to gain a bit of memory.\n",
        "\n",
        "learner|bs |lr  |bptt|wd  |drop_mult|`to_fp16(clip)`|fw acc%|bw acc%|avg acc%\n",
        "--     |--:|--: |--: |--: |--:      |--             |--:    |--:    |--:\n",
        "lm     |256|2e-2|  80|0.1 |1.0      |Yes; clip=0.1  |34.0075|37.2268|N/A\n",
        "cf     |128|1e-1| 70†|0.1‡|0.5      |No             |94.9560|94.7400|95.39\n",
        "\n",
        "    † both cf's used default bptt=70\n",
        "    ‡ forward cf used default wd=0.01\n",
        "\n",
        "* [fastai/course-nlp/nn-imdb-more.ipynb](https://nbviewer.jupyter.org/github/fastai/course-nlp/blob/master/nn-imdb-more.ipynb) (2019-06-12)\n",
        "\n",
        "learner|bs |lr        |bptt|wd  |drop_mult|`to_fp16(clip)`|fw acc%\n",
        "--     |--:|--:       |--: |--: |--:      |--             |--:\n",
        "lm     |128|1e-2*bs/48|  70|0.01|1.0      |Yes; clip=None |>27.8265†\n",
        "cf     |128|2e-2*bs/48|  70|0.01|0.5      |Yes; clip=None |94.8080\n",
        "\n",
        "    † forward lm's final accuracy wasn't shown"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF718toQqs83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensure GPU spec; T4 is for colab and one can change it for another env.\n",
        "gpu_list = !nvidia-smi -L\n",
        "if gpu_list[0].startswith('NVIDIA-SMI has failed'):\n",
        "  print('Runtime type should be GPU.')\n",
        "elif not gpu_list[0].startswith('GPU 0: Tesla T4'):\n",
        "  display(gpu_list)\n",
        "  print('Please reset all runtimes. We need a Tesla T4 to reproduce the experiments!')\n",
        "else:\n",
        "  display(gpu_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OcNDqMgrCca",
        "colab_type": "text"
      },
      "source": [
        "## Dependency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrjoIzboW09N",
        "colab_type": "text"
      },
      "source": [
        "### Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rwtTuykrEWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensure no surprises from conflict packages.\n",
        "!pip check"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bymTjo9wrz5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture pip_logs\n",
        "!pip install -U fastai==1.0.55 ipyexperiments jupyter-console==5.2.0 coverage==4.5.3 coveralls datascience albumentations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojbk71i1xaFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colab_vnd = 'application/vnd.colab-display-data+json'\n",
        "for o in pip_logs.outputs:\n",
        "  if colab_vnd in o.data and 'pip_warning' in o.data[colab_vnd]:\n",
        "    o.display()\n",
        "!pip check"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z1_46NArGi_",
        "colab_type": "text"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMm8qgQqD2eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import math\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import random\n",
        "from shutil import copytree\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from google.colab import drive\n",
        "\n",
        "from fastai import basic_data, basic_train, core\n",
        "from fastai import *\n",
        "from fastai.callbacks import CSVLogger\n",
        "from fastai.core import plt\n",
        "from fastai.text import *\n",
        "from fastprogress import fastprogress\n",
        "\n",
        "from ipyexperiments import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTVchfsRnLgI",
        "colab_type": "text"
      },
      "source": [
        "### Init\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnxWkqafNxvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Not set earlier because pip may require a restart.\n",
        "SESSN_START_T, = !date +%Y%m%dT%H%M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTX1BGNQN6VB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruGmJGQX9zh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stylize the plot of `lr_find()`\n",
        "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
        "plt.style.use(['dark_background','seaborn-poster','seaborn-deep'])\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.rcParams['axes.grid.axis'] = 'x'\n",
        "plt.rcParams['axes.grid.which'] = 'both'\n",
        "plt.rcParams['grid.alpha'] = 0.5\n",
        "plt.rcParams['grid.color'] = 'xkcd:lime green'\n",
        "plt.rcParams['grid.linestyle'] = ':'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db_RafAMN2mK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A special treatment for colab to decrease network traffic.\n",
        "fastprogress.NO_BAR = True\n",
        "master_bar, progress_bar = fastprogress.force_console_behavior()\n",
        "basic_train.master_bar, basic_train.progress_bar = master_bar, progress_bar\n",
        "basic_data.master_bar, basic_data.progress_bar = master_bar, progress_bar\n",
        "dataclass.master_bar, dataclass.progress_bar = master_bar, progress_bar\n",
        "text.master_bar, text.progress_bar = master_bar, progress_bar\n",
        "text.data.master_bar, text.data.progress_bar = master_bar, progress_bar\n",
        "core.master_bar, core.progress_bar = master_bar, progress_bar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDMmtPemp8H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COLAB_CONTENT_DIR_P = Path('/content')\n",
        "GD_DIR_P = COLAB_CONTENT_DIR_P / 'gdrive'\n",
        "drive.mount(str(GD_DIR_P), force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDRg1_MUpXjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_DIR_P = GD_DIR_P / 'My Drive/imdb'\n",
        "BASE_DIR_P.mkdir(parents=True, exist_ok=True)\n",
        "DATA_DIR_P = BASE_DIR_P / 'data'\n",
        "DATA_DIR_P.mkdir(parents=True, exist_ok=True)\n",
        "MDLS_DIR_P = BASE_DIR_P / 'models'\n",
        "MDLS_DIR_P.mkdir(parents=True, exist_ok=True)\n",
        "LOGS_DIR_P = BASE_DIR_P / 'logs'\n",
        "LOGS_DIR_P.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "FASTAI_DATA_DIR_P = Path('/root/.fastai/data')\n",
        "FASTAI_DATA_DIR_P.mkdir(parents=True, exist_ok=True)\n",
        "COLAB_DATA_DIR_P = COLAB_CONTENT_DIR_P / 'data'\n",
        "if not COLAB_DATA_DIR_P.is_symlink():\n",
        "  COLAB_DATA_DIR_P.symlink_to(FASTAI_DATA_DIR_P)\n",
        "if (COLAB_CONTENT_DIR_P / 'sample_data').exists():\n",
        "  !rm -rf /content/sample_data/\n",
        "\n",
        "IMDB_DATA_IN_COLAB_DIR_P = COLAB_DATA_DIR_P / 'imdb'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2RKejF7YdPR",
        "colab_type": "text"
      },
      "source": [
        "# Assign"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXGWsutHDaJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Hyper-parameters\n",
        "\n",
        "lm_bs = 128  #@param {type: \"number\"}\n",
        "cf_bs = 128  #@param {type: \"number\"}\n",
        "bptt = 70  #@param {type: \"number\"}\n",
        "moms = (0.8, 0.7)  #@param\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "lm_wd = 0.01  #@param {type: \"number\"}\n",
        "cf_wd = 0.01    #@param {type: \"number\"}\n",
        "lm_drop_mult = 1.0  #@param {type: \"number\"}\n",
        "cf_drop_mult = 0.5  #@param {type: \"number\"}\n",
        "\n",
        "FW_LM_DBNCH_FILE_S = f'fw_lm_dbnch-b{lm_bs}-bptt{bptt}.pkl'\n",
        "BW_LM_DBNCH_FILE_S = f'bw_lm_dbnch-b{lm_bs}-bptt{bptt}.pkl'\n",
        "FW_CF_DBNCH_FILE_S = f'fw_cf_dbnch-b{cf_bs}-bptt{bptt}.pkl'\n",
        "BW_CF_DBNCH_FILE_S = f'bw_cf_dbnch-b{cf_bs}-bptt{bptt}.pkl'\n",
        "\n",
        "VOCAB_FILE_P = DATA_DIR_P / f'imdb_vocab-b{lm_bs}-bptt{bptt}.pkl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRUf1ynuDJ6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMDb_CLASSES = ['neg', 'pos']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P381SP4eYxv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set num_workers to main process since the training set will be shuffled.\n",
        "n_dbnch_wrkrs = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt6CX7iTk3Vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One seed to rule pseudo-random number generators all.\n",
        "SEED = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEfPdqf-I-bZ",
        "colab_type": "text"
      },
      "source": [
        "# Define"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAhmWnGMZh7q",
        "colab_type": "text"
      },
      "source": [
        "## Random State Fixer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRZANfnLk6co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@dataclass\n",
        "class RandomStateHolder:\n",
        "  py3_state: Tuple[int, Tuple[int], Optional[float]]\n",
        "  np_state: Tuple[str, np.ndarray, int, int, float]\n",
        "  torch_state: torch.ByteTensor\n",
        "  cuda_states: List[torch.ByteTensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6ETnToMbEuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reset_random_states(seed=SEED):\n",
        "  random.seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  torch.manual_seed(SEED)  # This implies torch.cuda.manual_seed_all(SEED) now\n",
        "  # if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
        "  torch.backends.cudnn.deterministic = True  # About 15% slower but...\n",
        "  torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzBO0BdYlIW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_states():\n",
        "  return RandomStateHolder(\n",
        "      random.getstate(),\n",
        "      np.random.get_state(),\n",
        "      torch.get_rng_state(),\n",
        "      torch.cuda.get_rng_state_all()\n",
        "      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx_cqrWMlTn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_random_states(prngs_states: RandomStateHolder):\n",
        "  random.setstate(prngs_states.py3_state)\n",
        "  np.random.set_state(prngs_states.np_state)\n",
        "  torch.set_rng_state(prngs_states.torch_state)\n",
        "  torch.cuda.set_rng_state_all(prngs_states.cuda_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B0BEowQlVGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_random_states(prngs_states, file_path):\n",
        "  with open(file_path, 'wb') as f:\n",
        "    pickle.dump(prngs_states, f)\n",
        "    # print(f'Saved prngs_states: {prngs_states}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILzHtDPKlX7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_random_states(file_path):\n",
        "  with open(file_path, 'rb') as f:\n",
        "    prngs_states = pickle.load(f)\n",
        "    # print(f'Loaded prngs_states: {prngs_states}')\n",
        "  return prngs_states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJwkXFIyJlkB",
        "colab_type": "text"
      },
      "source": [
        "## LM-specific Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjm3439wUJUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_lm_databunch(data_dir_p, n_workers, bs, bptt, presort=True):\n",
        "  reset_random_states()\n",
        "  return (TextList.from_folder(data_dir_p, presort=presort)\n",
        "          .filter_by_folder(include=['train', 'test', 'unsup'])\n",
        "          .split_by_rand_pct(\n",
        "              0.1,\n",
        "              seed=SEED  # Set the seed again since in theory one can call np.random before this.\n",
        "          )\n",
        "          .label_for_lm()\n",
        "          .databunch(bs=bs, bptt=bptt, num_workers=n_workers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcZ9A0JNfA7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_lm_databunch(\n",
        "    data_dir_p,\n",
        "    lm_dbnch_fname_s,\n",
        "    bs=lm_bs,\n",
        "    n_workers=n_dbnch_wrkrs,\n",
        "    bptt=bptt\n",
        "):\n",
        "  reset_random_states()\n",
        "  return load_data(\n",
        "      data_dir_p, lm_dbnch_fname_s, bs, num_workers=n_workers, bptt=bptt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJnkgQiJqCyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_lm_learner_with_ulmfit(dbnch, drop_mult, base_path=BASE_DIR_P):\n",
        "  reset_random_states()\n",
        "  lm_learn = language_model_learner(dbnch, AWD_LSTM, drop_mult=drop_mult, path=base_path)\n",
        "  lm_learn = lm_learn.to_fp16()  # 2x faster\n",
        "  save_random_states(\n",
        "      get_random_states(),\n",
        "      DATA_DIR_P/'init_lm_learner_with_ulmfit-prng_states.pkl'\n",
        "  )\n",
        "  return lm_learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMflNyYdm-S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_lm_cycles(learner, lr, moms, wd, clbks=[], cycle_len=1):\n",
        "  set_random_states(load_random_states(\n",
        "      DATA_DIR_P/'init_lm_learner_with_ulmfit-prng_states.pkl'))\n",
        "  learner.fit_one_cycle(cycle_len, lr, moms=moms, wd=wd, callbacks=clbks)\n",
        "  save_random_states(\n",
        "      get_random_states(),\n",
        "      DATA_DIR_P/'init_lm_cycles-prng_states.pkl'\n",
        "      )\n",
        "  return learner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BngsYt2inEak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tune_lm_cycles(learner, lr, moms, wd, clbks=[], cycle_len=10):\n",
        "  set_random_states(load_random_states(\n",
        "      DATA_DIR_P/'init_lm_cycles-prng_states.pkl'))\n",
        "  learner.unfreeze()\n",
        "  learner.fit_one_cycle(cycle_len, lr, moms=moms, wd=wd, callbacks=clbks)\n",
        "  save_random_states(\n",
        "      get_random_states(),\n",
        "      DATA_DIR_P/'tune_lm_cycles-prng_states.pkl'\n",
        "      )\n",
        "  return learner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7ygpuHbJo0t",
        "colab_type": "text"
      },
      "source": [
        "## CF-specific Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPkphOtiXTHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_cf_databunch(\n",
        "    data_dir_p,\n",
        "    bs,\n",
        "    vocab,\n",
        "    tags=IMDb_CLASSES,\n",
        "    n_workers=n_dbnch_wrkrs,\n",
        "    presort=True\n",
        "):\n",
        "  reset_random_states()\n",
        "  tl = TextList.from_folder(data_dir_p, vocab=vocab, presort=presort)\n",
        "  ils = tl.split_by_folder(valid='test')\n",
        "  lls = ils.label_from_folder(classes=tags)\n",
        "  return lls.databunch(bs=bs, num_workers=n_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB5T78sWfQ8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_cf_databunch(\n",
        "    data_dir_p,\n",
        "    cf_dbnch_fname_s,\n",
        "    bs=cf_bs,\n",
        "    n_workers=n_dbnch_wrkrs\n",
        "):\n",
        "  reset_random_states()\n",
        "  return load_data(data_dir_p, cf_dbnch_fname_s, bs, num_workers=n_dbnch_wrkrs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_754QK6Ju61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_cf_learner_with_encoder(enc_name, dbnch, drop_mult, bptt=bptt, base_path=BASE_DIR_P):\n",
        "  reset_random_states()\n",
        "  cf_learn = text_classifier_learner(dbnch, AWD_LSTM, drop_mult=drop_mult, bptt=bptt, path=base_path, pretrained=False)\n",
        "  cf_learn = cf_learn.to_fp16()\n",
        "  cf_learn.load_encoder(enc_name)\n",
        "  save_random_states(\n",
        "      get_random_states(),\n",
        "      DATA_DIR_P/f'init_cf_learner_with_encoder-prng_states.pkl'\n",
        "  )\n",
        "  return cf_learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chGUzivkKYy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_cf_cycles(learner, lr, moms, wd, clbks, cycle_len=1):\n",
        "  set_random_states(load_random_states(\n",
        "      DATA_DIR_P/'init_cf_learner_with_encoder-prng_states.pkl'))\n",
        "  learner.fit_one_cycle(cycle_len, lr, moms=moms, wd=wd, callbacks=clbks)\n",
        "  save_random_states(\n",
        "      get_random_states(),\n",
        "      DATA_DIR_P/'init_cf_cycles-prng_states.pkl'\n",
        "      )\n",
        "\n",
        "  learner.path = COLAB_DATA_DIR_P\n",
        "  tmp_name = f'init_cf_tmp-{lr}'\n",
        "  tmp_p = learner.save(tmp_name, return_path=True, with_opt=True)\n",
        "  learner.load(tmp_name, purge=True, with_opt=True)\n",
        "  tmp_p.unlink()\n",
        "  learner.path = BASE_DIR_P\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  return learner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx3iwNXOLJQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tune_cf_cycles(\n",
        "    learner,\n",
        "    base_lr,\n",
        "    moms,\n",
        "    wd,\n",
        "    clbks_tuple,\n",
        "    cycle_len_tuple=(1,1,2),\n",
        "    freeze_steps=(-2,-3,None),\n",
        "    lr_decays=(2,2*2,2*2*5)\n",
        "):\n",
        "  prev_prng_states_pkl_path = DATA_DIR_P/'init_cf_cycles-prng_states.pkl'\n",
        "  cycle_id = 0\n",
        "\n",
        "  for cycle_len, freeze_step, lr_decay, clbks in zip(\n",
        "      cycle_len_tuple, freeze_steps, lr_decays, clbks_tuple):\n",
        "    if freeze_step is not None:\n",
        "      learner.freeze_to(freeze_step)\n",
        "    else:\n",
        "      learner.unfreeze()\n",
        "    lr = base_lr / lr_decay\n",
        "\n",
        "    set_random_states(load_random_states(prev_prng_states_pkl_path))\n",
        "    learner.fit_one_cycle(cycle_len, slice(lr/(2.6**4),lr), moms=moms, wd=wd, callbacks=clbks)\n",
        "    cycle_id += 1\n",
        "    prng_states_pkl_path = DATA_DIR_P/f'tune_cf_cycles-{cycle_id}-prng_states.pkl'\n",
        "    save_random_states(get_random_states(), prng_states_pkl_path)\n",
        "    prev_prng_states_pkl_path = prng_states_pkl_path\n",
        "    \n",
        "    learner.path = COLAB_DATA_DIR_P\n",
        "    tmp_name = f'tune_cf_tmp-{lr}'\n",
        "    tmp_p = learner.save(tmp_name, return_path=True, with_opt=True)\n",
        "    learner.load(tmp_name, purge=True, with_opt=True)\n",
        "    tmp_p.unlink()\n",
        "    learner.path = BASE_DIR_P\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  return learner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4puv1GrLOp5R",
        "colab_type": "text"
      },
      "source": [
        "# Fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3uudRrTXGq3",
        "colab_type": "text"
      },
      "source": [
        "## Forward LM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wopKpHoLPRj5",
        "colab_type": "text"
      },
      "source": [
        "### Process Data Once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIOwmjovkNjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb_data_downloaded_dir_p = untar_data(URLs.IMDB, dest=COLAB_DATA_DIR_P)\n",
        "assert imdb_data_downloaded_dir_p == IMDB_DATA_IN_COLAB_DIR_P"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUayc5jQ-ugt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if (DATA_DIR_P / FW_LM_DBNCH_FILE_S).exists():\n",
        "  print(f'Loading {DATA_DIR_P/FW_LM_DBNCH_FILE_S}.....')\n",
        "  fw_lm_dbnch = load_lm_databunch(DATA_DIR_P, FW_LM_DBNCH_FILE_S, lm_bs, n_dbnch_wrkrs, bptt)\n",
        "else:\n",
        "  print(f'Building {FW_LM_DBNCH_FILE_S}......')\n",
        "  fw_lm_dbnch = build_lm_databunch(IMDB_DATA_IN_COLAB_DIR_P, n_dbnch_wrkrs, lm_bs, bptt)\n",
        "# fw_lm_dbnch.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi-hqIkOflS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not VOCAB_FILE_P.exists():\n",
        "  print(f'Building {VOCAB_FILE_P}......')\n",
        "  fw_lm_dbnch.vocab.save(VOCAB_FILE_P)\n",
        "print(f'Loading {VOCAB_FILE_P}......')\n",
        "IMDB_VOC = Vocab.load(VOCAB_FILE_P)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt0DL_dOjokO",
        "colab_type": "text"
      },
      "source": [
        "### Use Persistent Path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm_heHy78zKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the databunch to a non-voatile path (e.g.: GDrive).\n",
        "if not (DATA_DIR_P / FW_LM_DBNCH_FILE_S).exists():\n",
        "  print(f'Saving {DATA_DIR_P/FW_LM_DBNCH_FILE_S}......')\n",
        "  fw_lm_dbnch.save(DATA_DIR_P / FW_LM_DBNCH_FILE_S)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX1Rpmq5-iL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The batch should look the same if the above efforts keep the reproducibility.\n",
        "# fw_lm_dbnch.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_IIOjBt8a0O",
        "colab_type": "text"
      },
      "source": [
        "### Find Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dflRYKkYtv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert fw_lm_dbnch.train_dl.batch_size == lm_bs\n",
        "lm_epoch_sz = math.ceil(len(fw_lm_dbnch.train_ds) / lm_bs)\n",
        "lr_find_num_it = math.ceil(lm_epoch_sz*0.3)  # `OneCycleScheduler`'s `pct_start=0.3`\n",
        "print(f'lm_epoch_sz\\t= {lm_epoch_sz}\\nlr_find_num_it\\t= {lr_find_num_it}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilR1t6qwMJ7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_find_scope = IPyExperimentsPytorch(cl_enable=False)\n",
        "fw_lm_dbnch = load_lm_databunch(DATA_DIR_P, FW_LM_DBNCH_FILE_S, lm_bs, n_dbnch_wrkrs, bptt)\n",
        "fw_lm_learn = init_lm_learner_with_ulmfit(fw_lm_dbnch, lm_drop_mult, COLAB_DATA_DIR_P)\n",
        "fw_lm_learn.lr_find(start_lr=1e-3, end_lr=1e-1, num_it=lr_find_num_it, wd=lm_wd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqTHVxFymu4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture lr_find_log\n",
        "fw_lm_learn.recorder.plot(suggestion=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwPXJA7z0nVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min(fw_lm_learn.recorder.losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ib1vF17DxLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_find_log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRKl8uPjblRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "((found_lr_desc, found_lr_val_str),\n",
        " (min_loss_desc, min_loss_val_str)\n",
        " ) = [line.split(': ') for line in lr_find_log.stdout.split('\\n') if line]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvzb13qas2rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_find_scope.keep_var_names('found_lr_val_str')\n",
        "del lr_find_scope\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKqmxK2NHvbY",
        "colab_type": "text"
      },
      "source": [
        "### Init-fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSLO-5xrJz3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "found_lm_lr = round(float(found_lr_val_str), 4)\n",
        "referred_lm_lr = 1e-2 * 128 / 48\n",
        "lm_lr = 1e-3 * 25  # 25 is the div_factor of slanted triangular lr scheduler\n",
        "print(f'found lm_lr     ={found_lm_lr}\\n'\n",
        "      f'referred lm_lr  ={referred_lm_lr}\\n'\n",
        "      f'designated lm_lr={lm_lr}')\n",
        "init_fw_lm_name = f'init_fw_lm-b{lm_bs}-bptt{bptt}-lr{lm_lr}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJHXFu6XqUlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_lm_scope = IPyExperimentsPytorch(cl_enable=False)\n",
        "fw_lm_dbnch = load_lm_databunch(DATA_DIR_P, FW_LM_DBNCH_FILE_S, lm_bs, n_dbnch_wrkrs, bptt)\n",
        "fw_lm_learn = init_lm_learner_with_ulmfit(fw_lm_dbnch, lm_drop_mult)\n",
        "init_fw_lm_log_p = LOGS_DIR_P / f'{SESSN_START_T}-{init_fw_lm_name}'  # w/o .csv\n",
        "init_fw_lm_clbks = [CSVLogger(fw_lm_learn, init_fw_lm_log_p, append=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7cIuvUXvRZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(init_fw_lm_name)\n",
        "fw_lm_learn = init_lm_cycles(fw_lm_learn, lm_lr, moms, lm_wd, init_fw_lm_clbks)\n",
        "# fw_lm_learn.csv_logger.read_logged_file()\n",
        "fw_lm_learn.save(init_fw_lm_name, with_opt=True)\n",
        "# (fw_lm_learn.path/fw_lm_learn.model_dir).ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVtTYwsyqLmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del init_lm_scope\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhGjAxk1IHCQ",
        "colab_type": "text"
      },
      "source": [
        "### Fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWkLGXW1HXOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tune_lm_lr = lm_lr / 10\n",
        "tune_fw_lm_name = f'tune_fw_lm-b{lm_bs}-bptt{bptt}-lr{tune_lm_lr}'\n",
        "fw_enc_name = f'fw_enc-b{lm_bs}-bptt{bptt}-lr{lm_lr}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dReSm50WhXG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tune_lm_scope = IPyExperimentsPytorch(cl_enable=False)\n",
        "fw_lm_dbnch = load_lm_databunch(DATA_DIR_P, FW_LM_DBNCH_FILE_S, lm_bs, n_dbnch_wrkrs, bptt)\n",
        "fw_lm_learn = init_lm_learner_with_ulmfit(fw_lm_dbnch, lm_drop_mult)\n",
        "fw_lm_learn = fw_lm_learn.load(init_fw_lm_name, purge=True, with_opt=True)\n",
        "tune_fw_lm_log_p = LOGS_DIR_P / f'{SESSN_START_T}-{tune_fw_lm_name}'\n",
        "tune_fw_lm_clbks = [CSVLogger(fw_lm_learn, tune_fw_lm_log_p, append=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vozz39UZ1GXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tune_fw_lm_name)\n",
        "fw_lm_learn = tune_lm_cycles(fw_lm_learn, tune_lm_lr, moms, lm_wd, tune_fw_lm_clbks)\n",
        "fw_lm_learn.save(tune_fw_lm_name, with_opt=True)\n",
        "fw_lm_learn.save_encoder(fw_enc_name)\n",
        "# (fw_lm_learn.path/fw_learn_lm.model_dir).ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvF0RhTu-uhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del tune_lm_scope\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8L_H4uC91mn",
        "colab_type": "text"
      },
      "source": [
        "## Forward CF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7L_vAAWiSVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if (DATA_DIR_P / FW_CF_DBNCH_FILE_S).exists():\n",
        "  print(f'Loading {DATA_DIR_P/FW_CF_DBNCH_FILE_S}.....')\n",
        "  fw_cf_dbnch = load_cf_databunch(DATA_DIR_P, FW_CF_DBNCH_FILE_S, cf_bs, n_dbnch_wrkrs)\n",
        "else:\n",
        "  print(f'Building {FW_CF_DBNCH_FILE_S}......')\n",
        "  fw_cf_dbnch = build_cf_databunch(IMDB_DATA_IN_COLAB_DIR_P, cf_bs, IMDB_VOC, n_workers=n_dbnch_wrkrs)\n",
        "# fw_cf_dbnch.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN8hrD2U-uhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the databunch to a non-voatile path (e.g.: GDrive).\n",
        "if not (DATA_DIR_P / FW_CF_DBNCH_FILE_S).exists():\n",
        "  print(f'Saving {DATA_DIR_P/FW_LM_DBNCH_FILE_S}......')\n",
        "  fw_cf_dbnch.save(DATA_DIR_P / FW_CF_DBNCH_FILE_S)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDnQT6dNHdi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cf_lr = lm_lr * 2\n",
        "init_fw_cf_name = f'init_fw_cf-b{cf_bs}-bptt{bptt}-lr{cf_lr}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC3kqw_I5auE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_cf_scope = IPyExperimentsPytorch(cl_enable=False)\n",
        "fw_cf_dbnch = load_cf_databunch(DATA_DIR_P, FW_CF_DBNCH_FILE_S, cf_bs, n_dbnch_wrkrs)\n",
        "fw_cf_learn = init_cf_learner_with_encoder(fw_enc_name, fw_cf_dbnch, cf_drop_mult, bptt)\n",
        "init_fw_cf_log_p = LOGS_DIR_P / f'{SESSN_START_T}-{init_fw_cf_name}'  # w/o .csv\n",
        "init_fw_cf_clbks = [CSVLogger(fw_cf_learn, init_fw_cf_log_p, append=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w56_704RCCht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(init_fw_cf_name)\n",
        "fw_cf_learn = init_cf_cycles(fw_cf_learn, cf_lr, moms, cf_wd, init_fw_cf_clbks)\n",
        "fw_cf_learn.save(init_fw_cf_name, with_opt=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc0RSW09q9qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del init_cf_scope\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynbxe3mCHfpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tune_fw_cf_name = f'tune_fw_cf-b{cf_bs}-bptt{bptt}-lr{cf_lr}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5frWCmrJq-ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tune_cf_scope = IPyExperimentsPytorch(cl_enable=False)\n",
        "fw_cf_dbnch = load_cf_databunch(DATA_DIR_P, FW_CF_DBNCH_FILE_S, cf_bs, n_dbnch_wrkrs)\n",
        "fw_cf_learn = init_cf_learner_with_encoder(fw_enc_name, fw_cf_dbnch, cf_drop_mult, bptt)\n",
        "fw_cf_learn = fw_cf_learn.load(init_fw_cf_name, purge=True, with_opt=True)\n",
        "tune_fw_cf_clbks_tuple = (\n",
        "    [CSVLogger(\n",
        "        fw_cf_learn,\n",
        "        LOGS_DIR_P / f'{SESSN_START_T}-{tune_fw_cf_name}-p{period}',\n",
        "        append=True)]\n",
        "    for period in range(1,4)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xXD8AdrCQhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tune_fw_cf_name)\n",
        "fw_cf_learn = tune_cf_cycles(fw_cf_learn, cf_lr, moms, cf_wd, tune_fw_cf_clbks_tuple)\n",
        "fw_cf_learn.save(tune_fw_cf_name, with_opt=True)\n",
        "fw_cf_learn.export(MDLS_DIR_P / f'export-{tune_fw_cf_name}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX8eTokHvB0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del tune_cf_scope\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}